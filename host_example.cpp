// host.cpp example, not exactly our code for HW4

#include <iostream>
#include <fstream>
#include <vector>
#include "common.hpp"

// These would be the functions generated by HLS (e.g., your top-level function)
extern void resnet_block_top(
    data_t input[IN_H][IN_W][IN_C],
    weight_t conv1_w[OUT_C][IN_C][K][K],
    weight_t conv2_w[OUT_C][OUT_C][K][K],
    weight_t skip_w[OUT_C][IN_C][SKIP_K][SKIP_K],
    data_t bn1_gamma[OUT_C], data_t bn1_beta[OUT_C], data_t bn1_mean[OUT_C], data_t bn1_var[OUT_C],
    data_t bn2_gamma[OUT_C], data_t bn2_beta[OUT_C], data_t bn2_mean[OUT_C], data_t bn2_var[OUT_C],
    data_t skip_gamma[OUT_C], data_t skip_beta[OUT_C], data_t skip_mean[OUT_C], data_t skip_var[OUT_C],
    data_t output[IN_H/2][IN_W/2][OUT_C] // Due to stride=2 in first conv
);

int main() {

    // -----------------------------
    // Load Input Tensor
    // -----------------------------
    data_t input[IN_H][IN_W][IN_C];

    // Example: reading from a binary file. Alternatively, generate random input.
    std::ifstream input_file("input_tensor.bin", std::ios::binary);
    if(!input_file) {
        // If file not found, generate random input as fallback
        srand(0);
        for (int h = 0; h < IN_H; h++) {
            for (int w = 0; w < IN_W; w++) {
                for (int c = 0; c < IN_C; c++) {
                    float val = ((float)rand()/(float)(RAND_MAX)) * 2.0f - 1.0f; // ~N(0,1) approx
                    input[h][w][c] = (data_t)val;
                }
            }
        }
    } else {
        // Assuming file has IN_H*IN_W*IN_C float values (or fixed-point values)
        float temp_val;
        for (int h = 0; h < IN_H; h++) {
            for (int w = 0; w < IN_W; w++) {
                for (int c = 0; c < IN_C; c++) {
                    input_file.read(reinterpret_cast<char*>(&temp_val), sizeof(float));
                    input[h][w][c] = (data_t)temp_val;
                }
            }
        }
        input_file.close();
    }

    // -----------------------------
    // Load Weights and BN Params
    // -----------------------------
    weight_t conv1_w[OUT_C][IN_C][K][K];
    weight_t conv2_w[OUT_C][OUT_C][K][K];
    weight_t skip_w[OUT_C][IN_C][SKIP_K][SKIP_K];

    data_t bn1_gamma[OUT_C], bn1_beta[OUT_C], bn1_mean[OUT_C], bn1_var[OUT_C];
    data_t bn2_gamma[OUT_C], bn2_beta[OUT_C], bn2_mean[OUT_C], bn2_var[OUT_C];
    data_t skip_gamma[OUT_C], skip_beta[OUT_C], skip_mean[OUT_C], skip_var[OUT_C];

    // Load from files (quantized weights)
    // Example: 
    std::ifstream conv1_file("conv1_weights.bin", std::ios::binary);
    for (int oc = 0; oc < OUT_C; oc++) {
        for (int ic = 0; ic < IN_C; ic++) {
            for (int kh = 0; kh < K; kh++) {
                for (int kw = 0; kw < K; kw++) {
                    float wval;
                    conv1_file.read(reinterpret_cast<char*>(&wval), sizeof(float));
                    conv1_w[oc][ic][kh][kw] = (weight_t)wval;
                }
            }
        }
    }
    conv1_file.close();

    // Repeat similarly for conv2_w, skip_w and BN parameters
    // In actual code, you must load them from the respective files obtained from the pretrained model.

    // For demonstration, assume random initialization (not correct for production!)
    for (int oc = 0; oc < OUT_C; oc++) {
        for (int ic = 0; ic < OUT_C; ic++) {
            for (int kh = 0; kh < K; kh++) {
                for (int kw = 0; kw < K; kw++) {
                    conv2_w[oc][ic][kh][kw] = (weight_t)((float)rand()/RAND_MAX - 0.5f);
                }
            }
        }
    }
    for (int oc = 0; oc < OUT_C; oc++) {
        for (int ic = 0; ic < IN_C; ic++) {
            skip_w[oc][ic][0][0] = (weight_t)((float)rand()/RAND_MAX - 0.5f);
        }
    }

    // BN parameters
    for (int oc = 0; oc < OUT_C; oc++) {
        bn1_gamma[oc] = (data_t)1.0f;
        bn1_beta[oc]  = (data_t)0.0f;
        bn1_mean[oc]  = (data_t)0.0f;
        bn1_var[oc]   = (data_t)1.0f;

        bn2_gamma[oc] = (data_t)1.0f;
        bn2_beta[oc]  = (data_t)0.0f;
        bn2_mean[oc]  = (data_t)0.0f;
        bn2_var[oc]   = (data_t)1.0f;

        skip_gamma[oc]= (data_t)1.0f;
        skip_beta[oc] = (data_t)0.0f;
        skip_mean[oc] = (data_t)0.0f;
        skip_var[oc]  = (data_t)1.0f;
    }

    // -----------------------------
    // Run the top-level block
    // -----------------------------
    data_t output[IN_H/2][IN_W/2][OUT_C];
    resnet_block_top(
        input,
        conv1_w,
        conv2_w,
        skip_w,
        bn1_gamma, bn1_beta, bn1_mean, bn1_var,
        bn2_gamma, bn2_beta, bn2_mean, bn2_var,
        skip_gamma, skip_beta, skip_mean, skip_var,
        output
    );

    // -----------------------------
    // Check output or save results
    // -----------------------------
    std::ofstream out_file("output_tensor.bin", std::ios::binary);
    for (int h = 0; h < IN_H/2; h++) {
        for (int w = 0; w < IN_W/2; w++) {
            for (int c = 0; c < OUT_C; c++) {
                float val = (float)output[h][w][c];
                out_file.write(reinterpret_cast<char*>(&val), sizeof(float));
            }
        }
    }
    out_file.close();

    std::cout << "Computation completed, output saved." << std::endl;
    return 0;
}
